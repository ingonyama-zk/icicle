
// Copyright 2023 Ingonyama
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by Ingonyama DO NOT EDIT

#include <cuda.h>
#include <cuda_runtime.h>
#include <stdbool.h>
// ve_mod_mult.h

#ifndef _BN254_VEC_MULT_H
#define _BN254_VEC_MULT_H

#ifdef __cplusplus
extern "C" {
#endif

typedef struct {
  cudaStream_t stream;   /**< Stream to use. Default value: 0. */
  int device_id;         /**< Index of the currently used GPU. Default value: 0. */
  cudaMemPool_t mempool; /**< Mempool to use. Default value: 0. */
} DeviceContext;

typedef struct BN254_scalar_t BN254_scalar_t;

int bn254AddCuda(
  BN254_scalar_t* vec_a,
  BN254_scalar_t* vec_b,
  int n,
  bool is_on_device,
  DeviceContext ctx,
  BN254_scalar_t* result
);

int bn254SubCuda(
  BN254_scalar_t* vec_a,
  BN254_scalar_t* vec_b,
  int n,
  bool is_on_device,
  DeviceContext ctx,
  BN254_scalar_t* result
);

int bn254MulCuda(
  BN254_scalar_t* vec_a,
  BN254_scalar_t* vec_b,
  int n,
  bool is_on_device,
  bool is_montgomery,
  DeviceContext ctx,
  BN254_scalar_t* result
);

#ifdef __cplusplus
}
#endif

#endif /* _BN254_VEC_MULT_H */
