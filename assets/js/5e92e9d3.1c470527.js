"use strict";(self.webpackChunkicicle_docs=self.webpackChunkicicle_docs||[]).push([[57657],{13265:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>c,default:()=>p,frontMatter:()=>t,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"api/cpp/matrix_ops","title":"Matrix Operations (C++ API)","description":"ICICLE provides efficient, flexible matrix operations for cryptographic and scientific computing, supporting both CPU and GPU backends. The API is designed for high performance, batch processing, and seamless device/host memory management.","source":"@site/versioned_docs/version-4.0.0/api/cpp/matrix_ops.md","sourceDirName":"api/cpp","slug":"/api/cpp/matrix_ops","permalink":"/api/cpp/matrix_ops","draft":false,"unlisted":false,"editUrl":"https://github.com/ingonyama-zk/icicle/tree/main/docs/versioned_docs/version-4.0.0/api/cpp/matrix_ops.md","tags":[],"version":"4.0.0","lastUpdatedAt":1752654507000,"frontMatter":{},"sidebar":"apisidebar","previous":{"title":"Serialization","permalink":"/api/cpp/serialization"},"next":{"title":"Golang Overview","permalink":"/gooverview"}}');var o=i(74848),r=i(28453);const t={},c="Matrix Operations (C++ API)",a={},l=[{value:"Configuration: <code>MatMulConfig</code>",id:"configuration-matmulconfig",level:2},{value:"Matrix Multiplication API",id:"matrix-multiplication-api",level:2},{value:"Example: Multiply Two Matrices on the GPU",id:"example-multiply-two-matrices-on-the-gpu",level:2},{value:"Notes",id:"notes",level:2},{value:"See Also",id:"see-also",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"matrix-operations-c-api",children:"Matrix Operations (C++ API)"})}),"\n",(0,o.jsx)(n.p,{children:"ICICLE provides efficient, flexible matrix operations for cryptographic and scientific computing, supporting both CPU and GPU backends. The API is designed for high performance, batch processing, and seamless device/host memory management."}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsxs)(n.h2,{id:"configuration-matmulconfig",children:["Configuration: ",(0,o.jsx)(n.code,{children:"MatMulConfig"})]}),"\n",(0,o.jsxs)(n.p,{children:["All matrix operations are controlled via the ",(0,o.jsx)(n.code,{children:"MatMulConfig"})," struct, which allows you to specify device placement, batching, transposition, and more."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-cpp",children:"struct MatMulConfig {\n    icicleStreamHandle stream = nullptr; // stream for async execution.\n    bool is_a_on_device = false;         // True if `a` resides on device memory.\n    bool is_b_on_device = false;         // True if `b` resides on device memory.\n    bool is_result_on_device = false;    // True to keep result on device, else host.\n    bool a_transposed = false;           // True if `a` is pre-transposed.\n    bool b_transposed = false;           // True if `b` is pre-transposed.\n    bool result_transposed = false;      // True to transpose the output.\n    bool is_async = false;               // True for non-blocking call; user must sync stream.\n    ConfigExtension* ext = nullptr;      // Optional backend-specific settings.\n  };\n"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Use ",(0,o.jsx)(n.code,{children:"default_mat_mul_config()"})," to get a default config for standard (single, synchronous, host) operation."]}),"\n",(0,o.jsxs)(n.li,{children:["For most users, set ",(0,o.jsx)(n.code,{children:"is_a_on_device"}),", ",(0,o.jsx)(n.code,{children:"is_b_on_device"}),", and ",(0,o.jsx)(n.code,{children:"is_result_on_device"})," to match your memory locations."]}),"\n",(0,o.jsxs)(n.li,{children:["Set ",(0,o.jsx)(n.code,{children:"is_async = true"})," for non-blocking GPU execution (requires explicit synchronization)."]}),"\n",(0,o.jsx)(n.li,{children:"Use batching for high throughput on large workloads."}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"matrix-multiplication-api",children:"Matrix Multiplication API"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-cpp",children:"template <typename T>\neIcicleError matmul(\n    const T* mat_a,\n    uint32_t nof_rows_a,\n    uint32_t nof_cols_a,\n    const T* mat_b,\n    uint32_t nof_rows_b,\n    uint32_t nof_cols_b,\n    const MatMulConfig& config,\n    T* mat_out);\n"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Inputs:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"mat_a"}),", ",(0,o.jsx)(n.code,{children:"mat_b"}),": Pointers to input matrices (row-major order)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"nof_rows_a"}),", ",(0,o.jsx)(n.code,{children:"nof_cols_a"}),": Dimensions of A"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"nof_rows_b"}),", ",(0,o.jsx)(n.code,{children:"nof_cols_b"}),": Dimensions of B"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"config"}),": Matrix operation configuration (see above)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"mat_out"}),": Pointer to output matrix (row-major, must be preallocated)"]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Requirements:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"nof_cols_a == nof_rows_b"})}),"\n",(0,o.jsx)(n.li,{children:"All pointers must be valid and point to memory on the correct device (host or GPU)"}),"\n",(0,o.jsx)(n.li,{children:"For batching, input/output pointers must be sized appropriately"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Returns:"})," ",(0,o.jsx)(n.code,{children:"eIcicleError"})," indicating success or failure"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Notes:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Supports both host and device memory (see config)"}),"\n",(0,o.jsx)(n.li,{children:"Supports batching and transposed inputs/outputs"}),"\n",(0,o.jsxs)(n.li,{children:["Asynchronous execution is available via ",(0,o.jsx)(n.code,{children:"is_async"})," and ",(0,o.jsx)(n.code,{children:"stream"})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"example-multiply-two-matrices-on-the-gpu",children:"Example: Multiply Two Matrices on the GPU"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-cpp",children:'#include "icicle/mat_ops.h"\n#include <vector>\n\nusing namespace icicle;\n\nint main() {\n    const uint32_t N = 512;\n    std::vector<float> a(N * N), b(N * N), c(N * N);\n    // ... fill a and b with data ...\n\n    // Move data to device (if needed) using your preferred memory management\n    // For this example, assume pointers a_dev, b_dev, c_dev are on device\n\n    MatMulConfig cfg = default_mat_mul_config();\n    cfg.is_a_on_device = true;\n    cfg.is_b_on_device = true;\n    cfg.is_result_on_device = true;\n\n    eIcicleError err = matmul(\n        a_dev, N, N,\n        b_dev, N, N,\n        cfg,\n        c_dev\n    );\n    // ... check err, copy c_dev back to host if needed ...\n}\n'})}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"notes",children:"Notes"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"All matrices are row-major by default; use the transposition flags for column-major or transposed operations."}),"\n",(0,o.jsx)(n.li,{children:"Batched operations are supported for high throughput."}),"\n",(0,o.jsx)(n.li,{children:"Both CPU and GPU (CUDA) backends are available out of the box."}),"\n",(0,o.jsx)(n.li,{children:"For more advanced usage (polynomial rings, custom types), see the full C++ API and backend headers."}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"see-also",children:"See Also"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"/api/cpp/vec_ops",children:"Vector Operations (vec_ops.md)"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"/apioverview",children:"NTT, MSM, and other primitives"})}),"\n",(0,o.jsx)(n.li,{children:"[Backend registration and extension (for advanced users)]"}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>c});var s=i(96540);const o={},r=s.createContext(o);function t(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:t(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);