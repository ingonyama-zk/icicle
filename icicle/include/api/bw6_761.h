// WARNING: This file is auto-generated by a script.
// Any changes made to this file may be overwritten.
// Please modify the code generation script instead.
// Path to the code generation script: scripts/gen_c_api.py

#pragma once
#ifndef BW6_761_API_H
#define BW6_761_API_H

#include <cuda_runtime.h>
#include "gpu-utils/device_context.cuh"
#include "curves/params/bw6_761.cuh"
#include "ntt/ntt.cuh"
#include "msm/msm.cuh"
#include "vec_ops/vec_ops.cuh"
#include "poseidon/poseidon.cuh"
#include "poseidon/tree/merkle.cuh"

extern "C" cudaError_t bw6_761G2PrecomputeMSMBases(
  bw6_761::g2_affine_t* bases,
  int bases_size,
  int precompute_factor,
  int _c,
  bool are_bases_on_device,
  device_context::DeviceContext& ctx,
  bw6_761::g2_affine_t* output_bases);

extern "C" cudaError_t bw6_761G2MSMCuda(
  const bw6_761::scalar_t* scalars, const bw6_761::g2_affine_t* points, int msm_size, msm::MSMConfig& config, bw6_761::g2_projective_t* out);

extern "C" cudaError_t bw6_761PrecomputeMSMBases(
  bw6_761::affine_t* bases,
  int bases_size,
  int precompute_factor,
  int _c,
  bool are_bases_on_device,
  device_context::DeviceContext& ctx,
  bw6_761::affine_t* output_bases);

extern "C" cudaError_t bw6_761MSMCuda(
  const bw6_761::scalar_t* scalars, const bw6_761::affine_t* points, int msm_size, msm::MSMConfig& config, bw6_761::projective_t* out);

extern "C" bool bw6_761G2Eq(bw6_761::g2_projective_t* point1, bw6_761::g2_projective_t* point2);

extern "C" void bw6_761G2ToAffine(bw6_761::g2_projective_t* point, bw6_761::g2_affine_t* point_out);

extern "C" void bw6_761G2GenerateProjectivePoints(bw6_761::g2_projective_t* points, int size);

extern "C" void bw6_761G2GenerateAffinePoints(bw6_761::g2_affine_t* points, int size);

extern "C" cudaError_t bw6_761G2AffineConvertMontgomery(
  bw6_761::g2_affine_t* d_inout, size_t n, bool is_into, device_context::DeviceContext& ctx);

extern "C" cudaError_t bw6_761G2ProjectiveConvertMontgomery(
  bw6_761::g2_projective_t* d_inout, size_t n, bool is_into, device_context::DeviceContext& ctx);

extern "C" cudaError_t bw6_761ECNTTCuda(
  const bw6_761::projective_t* input, int size, ntt::NTTDir dir, ntt::NTTConfig<bw6_761::scalar_t>& config, bw6_761::projective_t* output);

extern "C" bool bw6_761Eq(bw6_761::projective_t* point1, bw6_761::projective_t* point2);

extern "C" void bw6_761ToAffine(bw6_761::projective_t* point, bw6_761::affine_t* point_out);

extern "C" void bw6_761GenerateProjectivePoints(bw6_761::projective_t* points, int size);

extern "C" void bw6_761GenerateAffinePoints(bw6_761::affine_t* points, int size);

extern "C" cudaError_t bw6_761AffineConvertMontgomery(
  bw6_761::affine_t* d_inout, size_t n, bool is_into, device_context::DeviceContext& ctx);

extern "C" cudaError_t bw6_761ProjectiveConvertMontgomery(
  bw6_761::projective_t* d_inout, size_t n, bool is_into, device_context::DeviceContext& ctx);

extern "C" cudaError_t bw6_761ExtensionNTTCuda(
  const bw6_761::extension_t* input, int size, ntt::NTTDir dir, ntt::NTTConfig<bw6_761::scalar_t>& config, bw6_761::extension_t* output);

extern "C" cudaError_t bw6_761PoseidonHash(
  bw6_761::scalar_t* input,
  bw6_761::scalar_t* output,
  int number_of_states,
  int arity,
  const poseidon::PoseidonConstants<bw6_761::scalar_t>& constants,
  poseidon::PoseidonConfig& config);

extern "C" cudaError_t bw6_761BuildPoseidonMerkleTree(
  const bw6_761::scalar_t* leaves,
  bw6_761::scalar_t* digests,
  uint32_t height,
  int arity,
  poseidon::PoseidonConstants<bw6_761::scalar_t>& constants,
  merkle::TreeBuilderConfig& config);

extern "C" cudaError_t bw6_761MulCuda(
  bw6_761::scalar_t* vec_a, bw6_761::scalar_t* vec_b, int n, vec_ops::VecOpsConfig<bw6_761::scalar_t>& config, bw6_761::scalar_t* result);

extern "C" cudaError_t bw6_761AddCuda(
  bw6_761::scalar_t* vec_a, bw6_761::scalar_t* vec_b, int n, vec_ops::VecOpsConfig<bw6_761::scalar_t>& config, bw6_761::scalar_t* result);

extern "C" cudaError_t bw6_761SubCuda(
  bw6_761::scalar_t* vec_a, bw6_761::scalar_t* vec_b, int n, vec_ops::VecOpsConfig<bw6_761::scalar_t>& config, bw6_761::scalar_t* result);

extern "C" cudaError_t bw6_761TransposeMatrix(
  const bw6_761::scalar_t* input,
  uint32_t row_size,
  uint32_t column_size,
  bw6_761::scalar_t* output,
  device_context::DeviceContext& ctx,
  bool on_device,
  bool is_async);

extern "C" void bw6_761GenerateScalars(bw6_761::scalar_t* scalars, int size);

extern "C" cudaError_t bw6_761ScalarConvertMontgomery(
  bw6_761::scalar_t* d_inout, size_t n, bool is_into, device_context::DeviceContext& ctx);

extern "C" cudaError_t bw6_761InitializeDomain(
  bw6_761::scalar_t* primitive_root, device_context::DeviceContext& ctx, bool fast_twiddles_mode);

extern "C" cudaError_t bw6_761NTTCuda(
  const bw6_761::scalar_t* input, int size, ntt::NTTDir dir, ntt::NTTConfig<bw6_761::scalar_t>& config, bw6_761::scalar_t* output);

extern "C" cudaError_t bw6_761ReleaseDomain(device_context::DeviceContext& ctx);

extern "C" void bw6_761ExtensionGenerateScalars(bw6_761::extension_t* scalars, int size);

extern "C" cudaError_t bw6_761ExtensionScalarConvertMontgomery(
  bw6_761::extension_t* d_inout, size_t n, bool is_into, device_context::DeviceContext& ctx);

extern "C" cudaError_t bw6_761ExtensionMulCuda(
  bw6_761::extension_t* vec_a, bw6_761::extension_t* vec_b, int n, vec_ops::VecOpsConfig<bw6_761::extension_t>& config, bw6_761::extension_t* result);

extern "C" cudaError_t bw6_761ExtensionAddCuda(
  bw6_761::extension_t* vec_a, bw6_761::extension_t* vec_b, int n, vec_ops::VecOpsConfig<bw6_761::extension_t>& config, bw6_761::extension_t* result);

extern "C" cudaError_t bw6_761ExtensionSubCuda(
  bw6_761::extension_t* vec_a, bw6_761::extension_t* vec_b, int n, vec_ops::VecOpsConfig<bw6_761::extension_t>& config, bw6_761::extension_t* result);

extern "C" cudaError_t bw6_761ExtensionTransposeMatrix(
  const bw6_761::extension_t* input,
  uint32_t row_size,
  uint32_t column_size,
  bw6_761::extension_t* output,
  device_context::DeviceContext& ctx,
  bool on_device,
  bool is_async);

#endif